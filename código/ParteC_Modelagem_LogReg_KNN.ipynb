{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c1875f8",
   "metadata": {},
   "source": [
    "\n",
    "# **Parte C — Modelagem & Resultados**  \n",
    "**Dataset:** Heart Failure Prediction (918 instâncias combinadas das bases UCI)  \n",
    "**Modelos:** Regressão Logística e k-NN  \n",
    "**Autores:** _[preencha com os 3 nomes]_\n",
    "\n",
    "**Objetivo:** Comparar o desempenho de dois algoritmos clássicos (Regressão Logística e k-NN) para o problema de classificação binária de doença cardíaca, utilizando os dados **já pré-processados** (normalização, codificação e split treino/teste prontos).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64cada4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================\n",
    "# Imports\n",
    "# =========================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             classification_report, confusion_matrix, roc_curve, auc)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5899ab7",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Carregamento dos dados\n",
    "Carregamos os **arquivos pré-processados** gerados na Parte B:\n",
    "- `X_train.csv`, `X_test.csv`: atributos (features)\n",
    "- `y_train.csv`, `y_test.csv`: alvo (binário: 0 = sem doença, 1 = com doença)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c93e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================\n",
    "# Load data (assume CSVs in same directory as notebook)\n",
    "# =========================\n",
    "X_train = pd.read_csv('X_train.csv')\n",
    "X_test  = pd.read_csv('X_test.csv')\n",
    "y_train = pd.read_csv('y_train.csv').iloc[:, 0]\n",
    "y_test  = pd.read_csv('y_test.csv').iloc[:, 0]\n",
    "\n",
    "print(\"X_train:\", X_train.shape, \"| X_test:\", X_test.shape)\n",
    "print(\"y_train:\", y_train.shape, \"| y_test:\", y_test.shape)\n",
    "\n",
    "print(\"\\nProporção de classes (treino):\")\n",
    "print(y_train.value_counts(normalize=True).round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c924cf",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Funções auxiliares de avaliação\n",
    "Funções para avaliar o modelo e gerar métricas e gráficos (matriz de confusão e curva ROC).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a084858",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_model(model, X_tr, y_tr, X_te, y_te, model_name=\"Modelo\"):\n",
    "    model.fit(X_tr, y_tr)\n",
    "    y_pred = model.predict(X_te)\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_prob = model.predict_proba(X_te)[:, 1]\n",
    "    else:\n",
    "        try:\n",
    "            y_dec = model.decision_function(X_te)\n",
    "            y_prob = (y_dec - y_dec.min()) / (y_dec.max() - y_dec.min() + 1e-12)\n",
    "        except Exception:\n",
    "            y_prob = None\n",
    "\n",
    "    metrics = {\n",
    "        \"Modelo\": model_name,\n",
    "        \"Acuracia\": accuracy_score(y_te, y_pred),\n",
    "        \"Precisao\": precision_score(y_te, y_pred, zero_division=0),\n",
    "        \"Recall\": recall_score(y_te, y_pred, zero_division=0),\n",
    "        \"F1\": f1_score(y_te, y_pred, zero_division=0)\n",
    "    }\n",
    "    if y_prob is not None:\n",
    "        fpr, tpr, _ = roc_curve(y_te, y_prob)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        metrics[\"AUC\"] = roc_auc\n",
    "    else:\n",
    "        fpr, tpr, roc_auc = None, None, None\n",
    "\n",
    "    report = classification_report(y_te, y_pred, zero_division=0)\n",
    "    cm = confusion_matrix(y_te, y_pred)\n",
    "\n",
    "    return metrics, report, cm, (fpr, tpr, roc_auc), y_pred, y_prob\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, title=\"Matriz de Confusão\"):\n",
    "    fig, ax = plt.subplots()\n",
    "    cax = ax.imshow(cm, interpolation='nearest')\n",
    "    ax.set_title(title)\n",
    "    fig.colorbar(cax)\n",
    "    tick_marks = np.arange(2)\n",
    "    ax.set_xticks(tick_marks)\n",
    "    ax.set_yticks(tick_marks)\n",
    "    ax.set_xticklabels(['Sem doença (0)', 'Com doença (1)'])\n",
    "    ax.set_yticklabels(['Sem doença (0)', 'Com doença (1)'])\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], 'd'),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    ax.set_ylabel('Verdadeiro')\n",
    "    ax.set_xlabel('Predito')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_roc_curve(fpr, tpr, roc_auc, title=\"Curva ROC\"):\n",
    "    if fpr is None or tpr is None:\n",
    "        print(\"Este modelo não fornece probabilidades para plotar ROC.\")\n",
    "        return\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.3f}\")\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac53341",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Validação cruzada (k-fold) e busca de hiperparâmetros\n",
    "Usamos `StratifiedKFold` (k=5) para manter a proporção de classes em cada *fold*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676c8d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54accfbd",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Regressão Logística (baseline probabilístico)\n",
    "Fazemos `GridSearchCV` simples sobre **C** (força da regularização) e escolhemos `liblinear` para garantir convergência rápida.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab5c2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "log_reg = LogisticRegression(max_iter=1000, solver='liblinear', random_state=42)\n",
    "\n",
    "param_grid_lr = {\n",
    "    'C': [0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "    'penalty': ['l2']\n",
    "}\n",
    "\n",
    "grid_lr = GridSearchCV(log_reg, param_grid_lr, cv=cv, scoring='f1', n_jobs=-1)\n",
    "grid_lr.fit(X_train, y_train)\n",
    "\n",
    "best_lr = grid_lr.best_estimator_\n",
    "print(\"Melhor Regressão Logística:\", grid_lr.best_params_)\n",
    "print(\"F1 médio (CV):\", grid_lr.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaf6920",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "metrics_lr, report_lr, cm_lr, roc_lr, ypred_lr, yprob_lr = evaluate_model(best_lr, X_train, y_train, X_test, y_test, model_name=\"LogisticRegression\")\n",
    "\n",
    "print(\"== Regressão Logística: Métricas no Teste ==\")\n",
    "print(pd.Series(metrics_lr))\n",
    "\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(report_lr)\n",
    "\n",
    "plot_confusion_matrix(cm_lr, title=\"Matriz de Confusão — Regressão Logística\")\n",
    "plot_roc_curve(*roc_lr, title=\"Curva ROC — Regressão Logística\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48db144a",
   "metadata": {},
   "source": [
    "\n",
    "## 5. k-Nearest Neighbors (k-NN)\n",
    "Como os dados foram **normalizados** na Parte B, o k-NN é adequado. Fazemos grid em `k` (n_neighbors), métrica e pesos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944d3b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11, 13, 15],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "grid_knn = GridSearchCV(knn, param_grid_knn, cv=cv, scoring='f1', n_jobs=-1)\n",
    "grid_knn.fit(X_train, y_train)\n",
    "\n",
    "best_knn = grid_knn.best_estimator_\n",
    "print(\"Melhor KNN:\", grid_knn.best_params_)\n",
    "print(\"F1 médio (CV):\", grid_knn.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e3473d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "metrics_knn, report_knn, cm_knn, roc_knn, ypred_knn, yprob_knn = evaluate_model(best_knn, X_train, y_train, X_test, y_test, model_name=\"KNN\")\n",
    "\n",
    "print(\"== KNN: Métricas no Teste ==\")\n",
    "print(pd.Series(metrics_knn))\n",
    "\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(report_knn)\n",
    "\n",
    "plot_confusion_matrix(cm_knn, title=\"Matriz de Confusão — KNN\")\n",
    "plot_roc_curve(*roc_knn, title=\"Curva ROC — KNN\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9554988b",
   "metadata": {},
   "source": [
    "\n",
    "## 6. Comparação final\n",
    "Tabela agregando as principais métricas de cada modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f3b43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from caas_jupyter_tools import display_dataframe_to_user\n",
    "\n",
    "df_results = pd.DataFrame([metrics_lr, metrics_knn])\n",
    "cols = ['Modelo', 'Acuracia', 'Precisao', 'Recall', 'F1']\n",
    "if 'AUC' in df_results.columns:\n",
    "    cols.append('AUC')\n",
    "df_results = df_results[cols]\n",
    "\n",
    "print(df_results)\n",
    "display_dataframe_to_user(\"Resultados - LogReg vs KNN\", df_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82497e65",
   "metadata": {},
   "source": [
    "\n",
    "## 7. Observações rápidas (para o relatório)\n",
    "- **Regressão Logística**: baseline probabilístico, interpretável; bom equilíbrio entre **precisão** e **recall**.  \n",
    "- **k-NN**: sensível à escolha de *k* e à métrica; pode ter recall inferior se houver ruído.  \n",
    "- **Matriz de Confusão**: analise os **falsos negativos** (pacientes com doença predita como saudáveis) — isso é crítico em aplicações clínicas.  \n",
    "- **AUC/ROC**: útil para comparar a capacidade de separação entre as classes.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
